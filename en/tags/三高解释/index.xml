<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>三高解释 on Luenci</title>
    <link>https://luenci.com/en/tags/%E4%B8%89%E9%AB%98%E8%A7%A3%E9%87%8A/</link>
    <description>Recent content in 三高解释 on Luenci</description>
    <generator>Hugo -- 0.140.0</generator>
    <language>en</language>
    <atom:link href="https://luenci.com/en/tags/%E4%B8%89%E9%AB%98%E8%A7%A3%E9%87%8A/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>高并发,高可用,高性能</title>
      <link>https://luenci.com/en/posts/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AB%98%E6%80%A7%E8%83%BD/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://luenci.com/en/posts/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AB%98%E6%80%A7%E8%83%BD/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;原文链接：https://juejin.cn/post/6844903944955625479&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;一高并发&#34;&gt;一、高并发&lt;/h1&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证&lt;strong&gt;系统能够同时并行处理很多请求&lt;/strong&gt;。 高并发相关常用的一些指标有&lt;strong&gt;响应时间&lt;/strong&gt;（Response Time），&lt;strong&gt;吞吐量&lt;/strong&gt;（Throughput），&lt;strong&gt;每秒查询率&lt;/strong&gt;QPS（Query Per Second），&lt;strong&gt;并发用户数&lt;/strong&gt;等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;响应时间&lt;/strong&gt;：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;吞吐量&lt;/strong&gt;：单位时间内处理的请求数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;QPS&lt;/strong&gt;：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并发用户数&lt;/strong&gt;：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;如何提高并发能力&#34;&gt;如何提高并发能力&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;垂直扩展&lt;/p&gt;
&lt;p&gt;（Scale Up）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;增强单机硬件性能&lt;/strong&gt;（优先）：例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提升单机架构性能&lt;/strong&gt;：例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间。&lt;/li&gt;
&lt;li&gt;总结：管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是&lt;strong&gt;水平扩展&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;水平扩展&lt;/p&gt;
&lt;p&gt;（Scale Out）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，难点在于：如何在架构各层进行可水平扩展的设计。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;二高性能&#34;&gt;二、高性能&lt;/h1&gt;
&lt;h2 id=&#34;简介-1&#34;&gt;简介&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;简单的说，高性能（High Performance）就是指&lt;strong&gt;程序处理速度快，所占内存少，cpu占用率低&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;高并发和高性能是紧密相关的，提高应用的性能，是肯定可以提高系统的并发能力的。&lt;/li&gt;
&lt;li&gt;应用性能优化的时候，对于&lt;strong&gt;计算密集型&lt;/strong&gt;和&lt;strong&gt;IO密集型&lt;/strong&gt;还是有很大差别，需要分开来考虑。&lt;/li&gt;
&lt;li&gt;增加服务器资源（CPU、内存、服务器数量），绝大部分时候是可以提高应用的并发能力和性能 （前提是应用能够支持多任务并行计算，多服务器分布式计算才行），但也是要避免其中的一些问题，才可以更好的更有效率的利用服务器资源。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;提高性能的注意事项&#34;&gt;提高性能的注意事项&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;避免因为&lt;strong&gt;IO阻塞&lt;/strong&gt;让CPU闲置，导致CPU的浪费。&lt;/li&gt;
&lt;li&gt;避免&lt;strong&gt;多线程间增加锁&lt;/strong&gt;来保证同步，导致并行系统串行化。&lt;/li&gt;
&lt;li&gt;免创建、销毁、维护太多进程、线程，导致操作系统浪费资源在调度上。&lt;/li&gt;
&lt;li&gt;避免分布式系统中多服务器的关联，比如：依赖同一个mysql，程序逻辑中使用&lt;strong&gt;分布式锁&lt;/strong&gt;，导致瓶颈在mysql，分布式又变成串行化运算。&lt;/li&gt;
&lt;/ol&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>原文链接：https://juejin.cn/post/6844903944955625479</p>
</blockquote>
<h1 id="一高并发">一、高并发</h1>
<h2 id="简介">简介</h2>
<p>高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证<strong>系统能够同时并行处理很多请求</strong>。 高并发相关常用的一些指标有<strong>响应时间</strong>（Response Time），<strong>吞吐量</strong>（Throughput），<strong>每秒查询率</strong>QPS（Query Per Second），<strong>并发用户数</strong>等。</p>
<ul>
<li><strong>响应时间</strong>：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。</li>
<li><strong>吞吐量</strong>：单位时间内处理的请求数量。</li>
<li><strong>QPS</strong>：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。</li>
<li><strong>并发用户数</strong>：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。</li>
</ul>
<h2 id="如何提高并发能力">如何提高并发能力</h2>
<ul>
<li>
<p>垂直扩展</p>
<p>（Scale Up）</p>
<ol>
<li><strong>增强单机硬件性能</strong>（优先）：例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G。</li>
<li><strong>提升单机架构性能</strong>：例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间。</li>
<li>总结：管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是<strong>水平扩展</strong>。</li>
</ol>
</li>
<li>
<p>水平扩展</p>
<p>（Scale Out）</p>
<ol>
<li>只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，难点在于：如何在架构各层进行可水平扩展的设计。</li>
</ol>
</li>
</ul>
<h1 id="二高性能">二、高性能</h1>
<h2 id="简介-1">简介</h2>
<ol>
<li>简单的说，高性能（High Performance）就是指<strong>程序处理速度快，所占内存少，cpu占用率低</strong>。</li>
<li>高并发和高性能是紧密相关的，提高应用的性能，是肯定可以提高系统的并发能力的。</li>
<li>应用性能优化的时候，对于<strong>计算密集型</strong>和<strong>IO密集型</strong>还是有很大差别，需要分开来考虑。</li>
<li>增加服务器资源（CPU、内存、服务器数量），绝大部分时候是可以提高应用的并发能力和性能 （前提是应用能够支持多任务并行计算，多服务器分布式计算才行），但也是要避免其中的一些问题，才可以更好的更有效率的利用服务器资源。</li>
</ol>
<h2 id="提高性能的注意事项">提高性能的注意事项</h2>
<ol>
<li>避免因为<strong>IO阻塞</strong>让CPU闲置，导致CPU的浪费。</li>
<li>避免<strong>多线程间增加锁</strong>来保证同步，导致并行系统串行化。</li>
<li>免创建、销毁、维护太多进程、线程，导致操作系统浪费资源在调度上。</li>
<li>避免分布式系统中多服务器的关联，比如：依赖同一个mysql，程序逻辑中使用<strong>分布式锁</strong>，导致瓶颈在mysql，分布式又变成串行化运算。</li>
</ol>
<h1 id="三高可用">三、高可用</h1>
<h2 id="简介-2">简介</h2>
<p>高可用性（High Availability）通常来描述一个系统经过<strong>专门</strong>的设计，从而<strong>减少停工时间</strong>，而保持其服务的高度可用性(一直都能用)。</p>
<ul>
<li>全年停机不能超过<strong>31.5秒</strong>，</li>
<li><strong>6个9的性能</strong>：一直能用的概率为99.9999%</li>
</ul>
<h2 id="高可用注意事项">高可用注意事项</h2>
<ol>
<li><strong>避免单点</strong>：使用单个服务器，一旦该服务器意外宕机，将导致服务不可用</li>
<li><strong>使用“集群”</strong>：一台服务器挂了，还有其他后备服务器能够顶上</li>
<li><strong>心跳机制</strong>：用于<strong>监控</strong>服务器状态，挂了就进行<strong>故障修复</strong></li>
</ol>
<h1 id="四-举例">四、 举例</h1>
<h2 id="redis的主从复制">Redis的主从复制</h2>
<h3 id="1-应用场景">1. 应用场景</h3>
<p>电子商务网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是”多读少写”。</p>
<h3 id="2-实现原理">2. 实现原理</h3>
<p>一个Redis服务可以有多个该服务的复制品，这个Redis服务称为Master，其它复制称为Slaves。</p>
<p><img loading="lazy" src="https://gitee.com/luenci/RepoImg/raw/master/img/202108091405615.png" alt="image-20210809140552374"  />
</p>
<p>如图中所示，我们将一台Redis服务器作主库(Matser)，其他三台作为从库(Slave)，主库只负责写数据，每次有数据更新都将更新的数据同步到它所有的从库，而从库只负责读数据。这样一来，就有了两个好处：</p>
<ol>
<li><strong>读写分离</strong>：不仅可以提高服务器的负载能力，并且可以根据读请求的规模自由增加或者减少从库的数量。</li>
<li>数据被复制成了了好几份，就算有一台机器出现故障，也可以使用其他机器的数据快速恢复。</li>
</ol>
<p><strong>注意事项</strong>：在Redis主从模式中，一台主库可以拥有多个从库，但是一个从库只能隶属于一个主库。</p>]]></content:encoded>
    </item>
  </channel>
</rss>
