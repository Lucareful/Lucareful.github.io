<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>从0开始学架构 on Luenci</title>
    <link>https://luenci.com/en/categories/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E6%9E%B6%E6%9E%84/</link>
    <description>Recent content in 从0开始学架构 on Luenci</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en</language>
    <atom:link href="https://luenci.com/en/categories/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E6%9E%B6%E6%9E%84/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>高并发,高可用,高性能</title>
      <link>https://luenci.com/en/posts/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AB%98%E6%80%A7%E8%83%BD/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://luenci.com/en/posts/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AB%98%E6%80%A7%E8%83%BD/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;原文链接：https://juejin.cn/post/6844903944955625479&lt;/p&gt;&lt;/blockquote&gt;
&lt;h1 id=&#34;一高并发&#34;&gt;一、高并发&lt;/h1&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证&lt;strong&gt;系统能够同时并行处理很多请求&lt;/strong&gt;。 高并发相关常用的一些指标有&lt;strong&gt;响应时间&lt;/strong&gt;（Response Time），&lt;strong&gt;吞吐量&lt;/strong&gt;（Throughput），&lt;strong&gt;每秒查询率&lt;/strong&gt;QPS（Query Per Second），&lt;strong&gt;并发用户数&lt;/strong&gt;等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;响应时间&lt;/strong&gt;：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;吞吐量&lt;/strong&gt;：单位时间内处理的请求数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;QPS&lt;/strong&gt;：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并发用户数&lt;/strong&gt;：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;如何提高并发能力&#34;&gt;如何提高并发能力&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;垂直扩展&lt;/p&gt;
&lt;p&gt;（Scale Up）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;增强单机硬件性能&lt;/strong&gt;（优先）：例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提升单机架构性能&lt;/strong&gt;：例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间。&lt;/li&gt;
&lt;li&gt;总结：管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是&lt;strong&gt;水平扩展&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;水平扩展&lt;/p&gt;
&lt;p&gt;（Scale Out）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，难点在于：如何在架构各层进行可水平扩展的设计。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;二高性能&#34;&gt;二、高性能&lt;/h1&gt;
&lt;h2 id=&#34;简介-1&#34;&gt;简介&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;简单的说，高性能（High Performance）就是指&lt;strong&gt;程序处理速度快，所占内存少，cpu占用率低&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;高并发和高性能是紧密相关的，提高应用的性能，是肯定可以提高系统的并发能力的。&lt;/li&gt;
&lt;li&gt;应用性能优化的时候，对于&lt;strong&gt;计算密集型&lt;/strong&gt;和&lt;strong&gt;IO密集型&lt;/strong&gt;还是有很大差别，需要分开来考虑。&lt;/li&gt;
&lt;li&gt;增加服务器资源（CPU、内存、服务器数量），绝大部分时候是可以提高应用的并发能力和性能 （前提是应用能够支持多任务并行计算，多服务器分布式计算才行），但也是要避免其中的一些问题，才可以更好的更有效率的利用服务器资源。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;提高性能的注意事项&#34;&gt;提高性能的注意事项&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;避免因为&lt;strong&gt;IO阻塞&lt;/strong&gt;让CPU闲置，导致CPU的浪费。&lt;/li&gt;
&lt;li&gt;避免&lt;strong&gt;多线程间增加锁&lt;/strong&gt;来保证同步，导致并行系统串行化。&lt;/li&gt;
&lt;li&gt;免创建、销毁、维护太多进程、线程，导致操作系统浪费资源在调度上。&lt;/li&gt;
&lt;li&gt;避免分布式系统中多服务器的关联，比如：依赖同一个mysql，程序逻辑中使用&lt;strong&gt;分布式锁&lt;/strong&gt;，导致瓶颈在mysql，分布式又变成串行化运算。&lt;/li&gt;
&lt;/ol&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>原文链接：https://juejin.cn/post/6844903944955625479</p></blockquote>
<h1 id="一高并发">一、高并发</h1>
<h2 id="简介">简介</h2>
<p>高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证<strong>系统能够同时并行处理很多请求</strong>。 高并发相关常用的一些指标有<strong>响应时间</strong>（Response Time），<strong>吞吐量</strong>（Throughput），<strong>每秒查询率</strong>QPS（Query Per Second），<strong>并发用户数</strong>等。</p>
<ul>
<li><strong>响应时间</strong>：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。</li>
<li><strong>吞吐量</strong>：单位时间内处理的请求数量。</li>
<li><strong>QPS</strong>：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。</li>
<li><strong>并发用户数</strong>：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。</li>
</ul>
<h2 id="如何提高并发能力">如何提高并发能力</h2>
<ul>
<li>
<p>垂直扩展</p>
<p>（Scale Up）</p>
<ol>
<li><strong>增强单机硬件性能</strong>（优先）：例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G。</li>
<li><strong>提升单机架构性能</strong>：例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间。</li>
<li>总结：管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是<strong>水平扩展</strong>。</li>
</ol>
</li>
<li>
<p>水平扩展</p>
<p>（Scale Out）</p>
<ol>
<li>只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，难点在于：如何在架构各层进行可水平扩展的设计。</li>
</ol>
</li>
</ul>
<h1 id="二高性能">二、高性能</h1>
<h2 id="简介-1">简介</h2>
<ol>
<li>简单的说，高性能（High Performance）就是指<strong>程序处理速度快，所占内存少，cpu占用率低</strong>。</li>
<li>高并发和高性能是紧密相关的，提高应用的性能，是肯定可以提高系统的并发能力的。</li>
<li>应用性能优化的时候，对于<strong>计算密集型</strong>和<strong>IO密集型</strong>还是有很大差别，需要分开来考虑。</li>
<li>增加服务器资源（CPU、内存、服务器数量），绝大部分时候是可以提高应用的并发能力和性能 （前提是应用能够支持多任务并行计算，多服务器分布式计算才行），但也是要避免其中的一些问题，才可以更好的更有效率的利用服务器资源。</li>
</ol>
<h2 id="提高性能的注意事项">提高性能的注意事项</h2>
<ol>
<li>避免因为<strong>IO阻塞</strong>让CPU闲置，导致CPU的浪费。</li>
<li>避免<strong>多线程间增加锁</strong>来保证同步，导致并行系统串行化。</li>
<li>免创建、销毁、维护太多进程、线程，导致操作系统浪费资源在调度上。</li>
<li>避免分布式系统中多服务器的关联，比如：依赖同一个mysql，程序逻辑中使用<strong>分布式锁</strong>，导致瓶颈在mysql，分布式又变成串行化运算。</li>
</ol>
<h1 id="三高可用">三、高可用</h1>
<h2 id="简介-2">简介</h2>
<p>高可用性（High Availability）通常来描述一个系统经过<strong>专门</strong>的设计，从而<strong>减少停工时间</strong>，而保持其服务的高度可用性(一直都能用)。</p>
<ul>
<li>全年停机不能超过<strong>31.5秒</strong>，</li>
<li><strong>6个9的性能</strong>：一直能用的概率为99.9999%</li>
</ul>
<h2 id="高可用注意事项">高可用注意事项</h2>
<ol>
<li><strong>避免单点</strong>：使用单个服务器，一旦该服务器意外宕机，将导致服务不可用</li>
<li><strong>使用“集群”</strong>：一台服务器挂了，还有其他后备服务器能够顶上</li>
<li><strong>心跳机制</strong>：用于<strong>监控</strong>服务器状态，挂了就进行<strong>故障修复</strong></li>
</ol>
<h1 id="四-举例">四、 举例</h1>
<h2 id="redis的主从复制">Redis的主从复制</h2>
<h3 id="1-应用场景">1. 应用场景</h3>
<p>电子商务网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是”多读少写”。</p>
<h3 id="2-实现原理">2. 实现原理</h3>
<p>一个Redis服务可以有多个该服务的复制品，这个Redis服务称为Master，其它复制称为Slaves。</p>
<p><img loading="lazy" src="https://gitee.com/luenci/RepoImg/raw/master/img/202108091405615.png" alt="image-20210809140552374"  />
</p>
<p>如图中所示，我们将一台Redis服务器作主库(Matser)，其他三台作为从库(Slave)，主库只负责写数据，每次有数据更新都将更新的数据同步到它所有的从库，而从库只负责读数据。这样一来，就有了两个好处：</p>
<ol>
<li><strong>读写分离</strong>：不仅可以提高服务器的负载能力，并且可以根据读请求的规模自由增加或者减少从库的数量。</li>
<li>数据被复制成了了好几份，就算有一台机器出现故障，也可以使用其他机器的数据快速恢复。</li>
</ol>
<p><strong>注意事项</strong>：在Redis主从模式中，一台主库可以拥有多个从库，但是一个从库只能隶属于一个主库。</p>]]></content:encoded>
    </item>
    <item>
      <title>初探架构设计</title>
      <link>https://luenci.com/en/posts/%E5%88%9D%E6%8E%A2%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://luenci.com/en/posts/%E5%88%9D%E6%8E%A2%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;架构设计的主要目的是为了解决软件系统复杂度带来的问题&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;架构框架组件模块系统&#34;&gt;架构、框架、组件、模块、系统&lt;/h2&gt;
&lt;p&gt;OLAP（Online Analytical Processing）在线分析处理&lt;/p&gt;
&lt;p&gt;架构是顶层设计；框架是面向编程或配置的半成品；组件是从技术维度上的复用；模块是从业务维度上职责的划分；系统是相互协同可运行的实体。&lt;/p&gt;
&lt;h1 id=&#34;架构设计的目的&#34;&gt;架构设计的目的&lt;/h1&gt;
&lt;h2 id=&#34;明确架构设计是为了解决软件复杂度原则后&#34;&gt;明确“架构设计是为了解决软件复杂度”原则后&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;“这么多需求，从哪里开始下手进行架构设计呢？”
&lt;ul&gt;
&lt;li&gt;— 通过熟悉和理解需求，识别系统复杂性所在的地方，然后针对这些复杂点进行架构设计。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;“架构设计要考虑高性能、高可用、高扩展……这么多高 XX，全部设计完成估计要 1 个月，但老大只给了 1 周时间”
&lt;ul&gt;
&lt;li&gt;—架构设计并不是要面面俱到，不需要每个架构都具备高性能、高可用、高扩展等特点，而是要识别出复杂点然后有针对性地解决问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;“业界 A 公司的架构是 X，B 公司的方案是 Y，两个差别比较大，该参考哪一个呢？”
&lt;ul&gt;
&lt;li&gt;—理解每个架构方案背后所需要解决的复杂点，然后才能对比自己的业务复杂点，参考复杂点相似的方案。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其次，遵循这条准则能够让“老鸟”架构师有的放矢，而不是贪大求全。技术人员往往都希望自己能够做出最牛的东西，架构师也不例外，尤其是一些“老鸟”架构师，为了证明自己的技术牛，可能会陷入贪大求全的焦油坑而无法自拔。&lt;/p&gt;
&lt;p&gt;例如：“我们的系统一定要做到每秒 TPS 10 万”。&lt;/p&gt;
&lt;p&gt;“淘宝的架构是这么做的，我们也要这么做”。&lt;/p&gt;
&lt;p&gt;“Docker 现在很流行，我们的架构应该将 Docker 应用进来”。&lt;/p&gt;
&lt;p&gt;以上这些想法，如果拿“架构设计是为了解决软件复杂度”这个原则来衡量，就很容易判断。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“我们的系统一定要做到每秒 TPS 10 万”
&lt;ul&gt;
&lt;li&gt;—如果系统的复杂度不是在性能这部分，TPS 做到 10 万并没有什么用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;“淘宝的架构是这么做的，我们也要这么做”
&lt;ul&gt;
&lt;li&gt;—淘宝的架构是为了解决淘宝业务的复杂度而设计的，淘宝的业务复杂度并不就是我们的业务复杂度，绝大多数业务的用户量都不可能有淘宝那么大。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;“Docker 现在很流行，我们的架构应该将 Docker 应用进来
&lt;ul&gt;
&lt;li&gt;—Docker 不是万能的，只是为了解决资源重用和动态分配而设计的，如果我们的系统复杂度根本不是在这方面，引入 Docker 没有什么意义。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>架构设计的主要目的是为了解决软件系统复杂度带来的问题</p></blockquote>
<h2 id="架构框架组件模块系统">架构、框架、组件、模块、系统</h2>
<p>OLAP（Online Analytical Processing）在线分析处理</p>
<p>架构是顶层设计；框架是面向编程或配置的半成品；组件是从技术维度上的复用；模块是从业务维度上职责的划分；系统是相互协同可运行的实体。</p>
<h1 id="架构设计的目的">架构设计的目的</h1>
<h2 id="明确架构设计是为了解决软件复杂度原则后">明确“架构设计是为了解决软件复杂度”原则后</h2>
<ul>
<li>“这么多需求，从哪里开始下手进行架构设计呢？”
<ul>
<li>— 通过熟悉和理解需求，识别系统复杂性所在的地方，然后针对这些复杂点进行架构设计。</li>
</ul>
</li>
<li>“架构设计要考虑高性能、高可用、高扩展……这么多高 XX，全部设计完成估计要 1 个月，但老大只给了 1 周时间”
<ul>
<li>—架构设计并不是要面面俱到，不需要每个架构都具备高性能、高可用、高扩展等特点，而是要识别出复杂点然后有针对性地解决问题。</li>
</ul>
</li>
<li>“业界 A 公司的架构是 X，B 公司的方案是 Y，两个差别比较大，该参考哪一个呢？”
<ul>
<li>—理解每个架构方案背后所需要解决的复杂点，然后才能对比自己的业务复杂点，参考复杂点相似的方案。</li>
</ul>
</li>
</ul>
<p>其次，遵循这条准则能够让“老鸟”架构师有的放矢，而不是贪大求全。技术人员往往都希望自己能够做出最牛的东西，架构师也不例外，尤其是一些“老鸟”架构师，为了证明自己的技术牛，可能会陷入贪大求全的焦油坑而无法自拔。</p>
<p>例如：“我们的系统一定要做到每秒 TPS 10 万”。</p>
<p>“淘宝的架构是这么做的，我们也要这么做”。</p>
<p>“Docker 现在很流行，我们的架构应该将 Docker 应用进来”。</p>
<p>以上这些想法，如果拿“架构设计是为了解决软件复杂度”这个原则来衡量，就很容易判断。</p>
<ul>
<li>“我们的系统一定要做到每秒 TPS 10 万”
<ul>
<li>—如果系统的复杂度不是在性能这部分，TPS 做到 10 万并没有什么用。</li>
</ul>
</li>
<li>“淘宝的架构是这么做的，我们也要这么做”
<ul>
<li>—淘宝的架构是为了解决淘宝业务的复杂度而设计的，淘宝的业务复杂度并不就是我们的业务复杂度，绝大多数业务的用户量都不可能有淘宝那么大。</li>
</ul>
</li>
<li>“Docker 现在很流行，我们的架构应该将 Docker 应用进来
<ul>
<li>—Docker 不是万能的，只是为了解决资源重用和动态分配而设计的，如果我们的系统复杂度根本不是在这方面，引入 Docker 没有什么意义。</li>
</ul>
</li>
</ul>
<h2 id="简单的复杂度分析案例我来分析一个简单的案例">简单的复杂度分析案例我来分析一个简单的案例</h2>
<p>一起来看看如何将“架构设计的真正目的是为了解决软件系统复杂度带来的问题”这个指导思想应用到实践中。假设我们需要设计一个大学的学生管理系统，其基本功能包括登录、注册、成绩管理、课程管理等。当我们对这样一个系统进行架构设计的时候，首先应识别其复杂度到底体现在哪里。</p>
<ul>
<li>性能：一个学校的学生大约 1 ~ 2 万人，学生管理系统的访问频率并不高，平均每天单个学生的访问次数平均不到 1 次，因此性能这部分并不复杂，存储用 MySQL 完全能够胜任，缓存都可以不用，Web 服务器用 Nginx 绰绰有余。</li>
<li>可扩展性：学生管理系统的功能比较稳定，可扩展的空间并不大，因此可扩展性也不复杂。</li>
<li>高可用：学生管理系统即使宕机 2 小时，对学生管理工作影响并不大，因此可以不做负载均衡，更不用考虑异地多活这类复杂的方案了。但是，如果学生的数据全部丢失，修复是非常麻烦的，只能靠人工逐条修复，这个很难接受，因此需要考虑存储高可靠，这里就有点复杂了。我们需要考虑多种异常情况：机器故障、机房故障，针对机器故障，我们需要设计 MySQL 同机房主备方案；针对机房故障，我们需要设计 MySQL 跨机房同步方案。</li>
<li>安全性：学生管理系统存储的信息有一定的隐私性，例如学生的家庭情况，但并不是和金融相关的，也不包含强隐私（例如玉照、情感）的信息，因此安全性方面只要做 3 个事情就基本满足要求了：Nginx 提供 ACL 控制、用户账号密码管理、数据库访问权限控制。</li>
<li>成本：由于系统很简单，基本上几台服务器就能够搞定，对于一所大学来说完全不是问题，可以无需太多关注。还有其他方面，如果有兴趣，你可以自行尝试去分析。通过我上面的分析，可以看到这个方案的主要复杂性体现在存储可靠性上，需要保证异常的时候，不要丢失所有数据即可（丢失几个或者几十个学生的信息问题不大），对应的架构如下：</li>
</ul>
<p><img loading="lazy" src="https://gitee.com/luenci/RepoImg/raw/master/img/202108091404716.png" alt="image-20210809140457406"  />
</p>
<h1 id="高性能">高性能</h1>
<h2 id="1-任务分配">1. 任务分配</h2>
<p>任务分配的意思是指每台机器都可以处理完整的业务任务，不同的任务分配到不同的机器上执行。</p>
<h2 id="2任务分解">2.任务分解</h2>
<p>虽然系统拆分可能在某种程度上能提升业务处理性能，但提升性能也是有限的，不可能系统不拆分的时候业务处理耗时为 50ms，系统拆分后业务处理耗时只要 1ms，**因为最终决定业务处理性能的还是业务逻辑本身，业务逻辑本身没有发生大的变化下，理论上的性能是有一个上限的，系统拆分能够让性能逼近这个极限，但无法突破这个极限。**因此，任务分解带来的性能收益是有一个度的，并不是任务分解越细越好，而对于架构设计来说，如何把握这个粒度就非常关键了。</p>
<h1 id="高可用">高可用</h1>
<blockquote>
<p>系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。</p></blockquote>
<p>高性能增加机器目的在于“扩展”处理性能；高可用增加机器目的在于“冗余”处理单元。</p>
<h2 id="计算高可用">计算高可用</h2>
<p>计算有一个特点就是无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的，所以将计算从一台机器迁移到另外一台机器，对业务并没有什么影响。</p>
<p>你可能会发现，这个双机的架构图和上期“高性能”讲到的双机架构图是一样的，因此复杂度也是类似的，具体表现为：</p>
<p>需要增加一个任务分配器，选择合适的任务分配器也是一件复杂的事情，需要综合考虑性能、成本、可维护性、可用性等各方面因素。</p>
<p>任务分配器和真正的业务服务器之间有连接和交互，需要选择合适的连接方式，并且对连接进行管理。例如，连接建立、连接检测、连接中断后如何处理等。</p>
<p>任务分配器需要增加分配算法。例如，常见的双机算法有主备、主主，主备方案又可以细分为冷备、温备、热备。</p>
<p><img loading="lazy" src="https://gitee.com/luenci/RepoImg/raw/master/img/202108091404259.png" alt="image-20210809140416757"  />
</p>
<h2 id="存储高可用">存储高可用</h2>
<p>综合分析，无论是正常情况下的传输延迟，还是异常情况下的传输中断，都会导致系统的数据在某个时间点或者时间段是不一致的，而数据的不一致又会导致业务问题；但如果完全不做冗余，系统的整体高可用又无法保证，所以存储高可用的难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响。</p>
<p>计算机内部复杂度最关键的地方就是操作系统。计算机性能的发展本质上是由硬件发展驱动的，尤其是 CPU 的性能发展。著名的“摩尔定律”表明了 CPU 的处理能力每隔 18 个月就翻一番；而将硬件性能充分发挥出来的关键就是操作系统，所以操作系统本身其实也是跟随硬件的发展而发展的，操作系统是软件系统的运行环境，操作系统的复杂度直接决定了软件系统的复杂度。</p>
<h2 id="高性能方案">高性能方案</h2>
<p>数据库读写分离（主从集群）</p>
<ul>
<li>主从复制延迟和分配机制。</li>
</ul>
<p>读写分离分散了数据库读写操作的压力，但没有分散存储压力，当数据量达到千万甚至上亿条的时候，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在这几个方面：</p>
<ul>
<li>数据量太大，读写的性能会下降，即使有索引，索引也会变得很大，性能同样会下降。</li>
<li>数据文件会变得很大，数据库备份和恢复需要耗费很长时间。</li>
<li>数据文件越大，极端情况下丢失数据的风险越高（例如，机房火灾导致数据库主备机都发生故障）。</li>
</ul>
<h2 id="分库分表">分库分表</h2>
<p>业务分库</p>
<ul>
<li>业务分库指的是按照业务模块将数据分散到不同的数据库服务器。</li>
</ul>
<h2 id="分表">分表</h2>
<p>将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。例如，淘宝的几亿用户数据，如果全部存放在一台数据库服务器的一张表中，肯定是无法满足性能要求的，此时就需要对单表数据进行拆分。</p>
<h3 id="垂直分表">垂直分表</h3>
<ul>
<li>垂直分表适合将表中某些不常用且占了大量空间的列拆分出去。</li>
</ul>
<h2 id="水平分表">水平分表</h2>
<ul>
<li>当看到表的数据量达到千万级别时，作为架构师就要警觉起来，因为这很可能是架构的性能瓶颈或者隐患。</li>
</ul>
<h2 id="小结">小结</h2>
<p>这些操作依次尝试</p>
<p>1.做硬件优化，例如从机械硬盘改成使用固态硬盘，当然固态硬盘不适合服务器使用，只是举个例子</p>
<p>2.先做数据库服务器的调优操作，例如增加索引，oracle有很多的参数调整;</p>
<p>3.引入缓存技术，例如Redis，减少数据库压力</p>
<p>4.程序与数据库表优化，重构，例如根据业务逻辑对程序逻辑做优化，减少不必要的查询;</p>
<p>5.在这些操作都不能大幅度优化性能的情况下，不能满足将来的发展，再考虑分库分表，也要有预估性</p>
<h1 id="高性能nosql">高性能NoSQL</h1>
<p>常见的 NoSQL 方案分为 4 类。</p>
<ul>
<li>K-V 存储：解决关系数据库无法存储数据结构的问题，以 Redis 为代表。</li>
<li>文档数据库：解决关系数据库强 schema 约束的问题，以 MongoDB 为代表。</li>
<li>列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 HBase 为代表。</li>
<li>全文搜索引擎：解决关系数据库的全文搜索性能问题，以 Elasticsearch 为代表。</li>
</ul>
<h1 id="缓存">缓存</h1>
<h2 id="缓存穿透">缓存穿透</h2>
<p>缓存穿透是指缓存没有发挥作用，业务系统虽然去缓存查询数据，但缓存中没有数据，业务系统需要再次去存储系统查询数据。通常情况下有两种情况：</p>
<ol>
<li>存储数据不存在</li>
<li>缓存数据生成耗费大量时间或者资源</li>
</ol>
<h2 id="缓存雪崩">缓存雪崩</h2>
<p>缓存雪崩是指当缓存失效（过期）后引起系统性能急剧下降的情况。当缓存过期被清除后，业务系统需要重新生成缓存，因此需要再次访问存储系统，再次进行运算，这个处理步骤耗时几十毫秒甚至上百毫秒。而对于一个高并发的业务系统来说，几百毫秒内可能会接到几百上千个请求。由于旧的缓存已经被清除，新的缓存还未生成，并且处理这些请求的线程都不知道另外有一个线程正在生成缓存，因此所有的请求都会去重新生成缓存，都会去访问存储系统，从而对存储系统造成巨大的性能压力。这些压力又会拖慢整个系统，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。</p>]]></content:encoded>
    </item>
  </channel>
</rss>
